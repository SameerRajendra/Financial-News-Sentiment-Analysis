{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e111ca4e-6f6c-4982-84af-6e855780db4e",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qq pandas datasets scikit-learn transformers numpy pandas torch evaluate transformers[torch] accelerate psycopg2-binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ca10c613",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
        "                          TrainingArguments, Trainer, DataCollatorWithPadding)\n",
        "import evaluate, numpy as np, torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "55cde1e4-9395-4f55-855e-6f251ec978bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "def mapper(p):\n",
        "    if p < -0.2:\n",
        "        return 0          # negative\n",
        "    elif p > 0.2:\n",
        "        return 2          # positive\n",
        "    else:\n",
        "        return 1          # neutral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "758eab6c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_158/2616319439.py:2: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('full_stock_news.csv')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ticker                      time  \\\n",
            "0    SYY 2011-05-09 00:00:00+00:00   \n",
            "1    BBY 2011-06-14 00:00:00+00:00   \n",
            "2   SNEX 2012-01-29 00:00:00+00:00   \n",
            "3    JEF 2012-03-05 00:00:00+00:00   \n",
            "4    JEF 2012-06-04 00:00:00+00:00   \n",
            "\n",
            "                                            title  \\\n",
            "0          RIMM Hung Up, Dollar Thrifty Gassed Up   \n",
            "1  Best Buy Rallies as Dollar Thrifty Gets a Flat   \n",
            "2               \\nTamara Walsh  |  Jan 29, 2012\\n   \n",
            "3            Would Warren Buffett Buy Apple Now?    \n",
            "4                  Just Walk Away From Chesapeake   \n",
            "\n",
            "                                             content  sentiment_polarity  \n",
            "0  Options quiet but action seen in Research In M...               0.000  \n",
            "1  Trading midday sees action in Best Buy (NYSE: ...               0.637  \n",
            "2  Companies gaining market share even in a strug...               0.296  \n",
            "3  Apple stock has run up by 44% since mid-Decemb...               0.000  \n",
            "4  Sure it's cheap, but it also has far too many ...              -0.440  \n",
            "ticker                             object\n",
            "time                  datetime64[ns, UTC]\n",
            "title                              object\n",
            "content                            object\n",
            "sentiment_polarity                float64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# ── 1. Fetch data from QuestDB ─────────────────────────────────\n",
        "conn_params = {\n",
        "    \"host\": \"quest.amudhan.me\",\n",
        "    \"port\": 8812,\n",
        "    \"database\": \"qdb\",\n",
        "    \"user\": \"admin\",\n",
        "    \"password\": \"redacted\"\n",
        "}\n",
        "\n",
        "try:\n",
        "    conn = psycopg2.connect(**conn_params)\n",
        "\n",
        "    query = \"\"\"\n",
        "    SELECT * FROM stock_news WHERE time BETWEEN '2005-01-01T00:00:00Z' AND '2024-12-31T23:59:59Z'\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    df_test = pd.read_sql_query(query, conn)\n",
        "    conn.close()\n",
        "\n",
        "except Exception as e:\n",
        "    raise Exception(f\"QuestDB error: {e}\")\n",
        "\n",
        "# ── 2. Inspect & clean basic types ─────────────────────────────────\n",
        "# Make sure timestamps are proper datetime objects\n",
        "df[\"time\"] = pd.to_datetime(df[\"time\"], errors=\"coerce\")\n",
        "\n",
        "# Drop rows with missing content, if any\n",
        "df = df.dropna(subset=[\"content\"])\n",
        "\n",
        "# ── 3. (Optional) keep just the columns you’ll feed to a model ─────\n",
        "cols_for_model = [\n",
        "    \"ticker\",\n",
        "    \"time\",\n",
        "    \"title\",\n",
        "    \"content\",\n",
        "    \"sentiment_polarity\"   # if you want the pre‑computed label\n",
        "]\n",
        "df_model = df[cols_for_model].copy()\n",
        "# Coerce any non‑numeric value to NaN, keep valid floats\n",
        "df[\"sentiment_polarity\"] = pd.to_numeric(df[\"sentiment_polarity\"], errors=\"coerce\")\n",
        "\n",
        "# Drop the rows that became NaN (i.e. were non‑numeric originally)\n",
        "df = df.dropna(subset=[\"sentiment_polarity\"]).reset_index(drop=True)\n",
        "\n",
        "\n",
        "# ── 4. Quick sanity check ──────────────────────────────────────────\n",
        "print(df_model.head())\n",
        "print(df_model.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a025e5e8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "2    313958\n",
            "0     28967\n",
            "1     27755\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df[\"label\"] = df[\"sentiment_polarity\"].apply(mapper)\n",
        "print(df[\"label\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0b525a90",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "class weights: tensor([4.2655, 4.4518, 0.3936], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "labels = np.array(df[\"label\"])          # [0,1,2]\n",
        "weights = compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels)\n",
        "class_wt = torch.tensor(weights, dtype=torch.float32).to(\"cuda\")\n",
        "print(\"class weights:\", class_wt)       # e.g. tensor([2.95, 6.45, 1.00])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3723ca59",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df, eval_df = train_test_split(df[[\"content\", \"label\"]],\n",
        "                                     test_size=0.1, stratify=df[\"label\"], random_state=42)\n",
        "\n",
        "ds = DatasetDict({\n",
        "    \"train\": Dataset.from_pandas(train_df.reset_index(drop=True)),\n",
        "    \"eval\" : Dataset.from_pandas(eval_df.reset_index(drop=True))\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3f61210c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": "",
            "text/plain": [
              "Map:   0%|          | 0/333612 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": "",
            "text/plain": [
              "Map:   0%|          | 0/37068 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name = \"EleutherAI/gpt-neo-125M\"\n",
        "tokenizer   = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token                         # GPT needs an explicit pad\n",
        "\n",
        "def tok_fn(batch):\n",
        "    return tokenizer(batch[\"content\"],\n",
        "                     truncation=True,\n",
        "                     padding=\"max_length\",\n",
        "                     max_length=256)\n",
        "\n",
        "ds = ds.map(tok_fn, batched=True, remove_columns=[\"content\"])\n",
        "ds.set_format(\"torch\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f180eeb5",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
        "model.config.pad_token_id = tokenizer.pad_token_id  # let HF know"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f9db8c6e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✔ TrainingArguments initialised on stable release.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./gptneo125_sentiment\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=128,\n",
        "    per_device_eval_batch_size=128,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "print(\"✔ TrainingArguments initialised on stable release.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6ea67f10",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformers version -> 4.51.3\n",
            "Python executable   -> /usr/bin/python\n",
            "Platform            -> Linux-6.8.0-57-generic-x86_64-with-glibc2.35\n"
          ]
        }
      ],
      "source": [
        "import transformers, sys, platform\n",
        "print(\"Transformers version ->\", transformers.__version__)\n",
        "print(\"Python executable   ->\", sys.executable)\n",
        "print(\"Platform            ->\", platform.platform())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7f0545bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits  = outputs.logits\n",
        "        loss = F.cross_entropy(logits, labels, weight=class_wt)\n",
        "        return (loss, outputs) if return_outputs else loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0128ef4e",
      "metadata": {},
      "outputs": [],
      "source": [
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=preds, references=labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0a79d78b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import evaluate, numpy as np\n",
        "f1  = evaluate.load(\"f1\")\n",
        "acc = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"macro_f1\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
        "        \"accuracy\": acc.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d852ae41",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2760/1017920106.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = WeightedTrainer(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:271: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  arr = np.array(obj)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:271: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  arr = np.array(obj)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:271: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  arr = np.array(obj)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7821' max='7821' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7821/7821 34:11, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.359800</td>\n",
              "      <td>0.337664</td>\n",
              "      <td>0.753674</td>\n",
              "      <td>0.878440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.207700</td>\n",
              "      <td>0.296677</td>\n",
              "      <td>0.825481</td>\n",
              "      <td>0.924382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.344247</td>\n",
              "      <td>0.852192</td>\n",
              "      <td>0.939382</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "('./gptneo125_sentiment/final/tokenizer_config.json',\n",
              " './gptneo125_sentiment/final/special_tokens_map.json',\n",
              " './gptneo125_sentiment/final/vocab.json',\n",
              " './gptneo125_sentiment/final/merges.txt',\n",
              " './gptneo125_sentiment/final/added_tokens.json',\n",
              " './gptneo125_sentiment/final/tokenizer.json')"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=8)\n",
        "\n",
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=ds[\"train\"],\n",
        "    eval_dataset =ds[\"eval\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,  # macro-F1 below\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train()\n",
        "trainer.save_model(\"./gptneo125_sentiment/final\")\n",
        "tokenizer.save_pretrained(\"./gptneo125_sentiment/final\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b6e858c1-1c7f-4d22-90e9-fc10e62b3de1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./gptneo125_sentiment/final/tokenizer_config.json',\n",
              " './gptneo125_sentiment/final/special_tokens_map.json',\n",
              " './gptneo125_sentiment/final/vocab.json',\n",
              " './gptneo125_sentiment/final/merges.txt',\n",
              " './gptneo125_sentiment/final/added_tokens.json',\n",
              " './gptneo125_sentiment/final/tokenizer.json')"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.save_model(\"./gptneo125_sentiment/final\")\n",
        "tokenizer.save_pretrained(\"./gptneo125_sentiment/final\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "34aba130-fded-45f2-a5dc-e34f40f70f47",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticker</th>\n",
              "      <th>time</th>\n",
              "      <th>title</th>\n",
              "      <th>content</th>\n",
              "      <th>link</th>\n",
              "      <th>symbols</th>\n",
              "      <th>tags</th>\n",
              "      <th>sentiment_polarity</th>\n",
              "      <th>sentiment_neg</th>\n",
              "      <th>sentiment_neu</th>\n",
              "      <th>sentiment_pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KHC</td>\n",
              "      <td>2025-01-01 00:00:00+00:00</td>\n",
              "      <td>Is Kraft Heinz Stock in Trouble?</td>\n",
              "      <td>Is Kraft Heinz Stock in Trouble?</td>\n",
              "      <td>https://www.fool.com/investing/2025/01/01/is-k...</td>\n",
              "      <td>KHC.US</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.402</td>\n",
              "      <td>0.351</td>\n",
              "      <td>0.649</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GE</td>\n",
              "      <td>2025-01-01 09:01:43+00:00</td>\n",
              "      <td>General Industrial Machinery Stocks Q3 Results...</td>\n",
              "      <td>General Industrial Machinery Stocks Q3 Results...</td>\n",
              "      <td>https://finance.yahoo.com/news/general-industr...</td>\n",
              "      <td>GE.MX,GE.US,HI.US,HON.US,IEP.US,LXFR.US</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.998</td>\n",
              "      <td>0.043</td>\n",
              "      <td>0.817</td>\n",
              "      <td>0.140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IEP</td>\n",
              "      <td>2025-01-01 09:01:43+00:00</td>\n",
              "      <td>General Industrial Machinery Stocks Q3 Results...</td>\n",
              "      <td>General Industrial Machinery Stocks Q3 Results...</td>\n",
              "      <td>https://finance.yahoo.com/news/general-industr...</td>\n",
              "      <td>GE.MX,GE.US,HI.US,HON.US,IEP.US,LXFR.US</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.998</td>\n",
              "      <td>0.043</td>\n",
              "      <td>0.817</td>\n",
              "      <td>0.140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HON</td>\n",
              "      <td>2025-01-01 09:01:43+00:00</td>\n",
              "      <td>General Industrial Machinery Stocks Q3 Results...</td>\n",
              "      <td>General Industrial Machinery Stocks Q3 Results...</td>\n",
              "      <td>https://finance.yahoo.com/news/general-industr...</td>\n",
              "      <td>GE.MX,GE.US,HI.US,HON.US,IEP.US,LXFR.US</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.998</td>\n",
              "      <td>0.043</td>\n",
              "      <td>0.817</td>\n",
              "      <td>0.140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CMI</td>\n",
              "      <td>2025-01-01 09:02:48+00:00</td>\n",
              "      <td>Heavy Transportation Equipment Stocks Q3 Recap...</td>\n",
              "      <td>Heavy Transportation Equipment Stocks Q3 Recap...</td>\n",
              "      <td>https://finance.yahoo.com/news/heavy-transport...</td>\n",
              "      <td>0I58.LSE,BLBD.US,CMI.US,CUM.DU,CUM.F,CUM.MU,RE...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.999</td>\n",
              "      <td>0.031</td>\n",
              "      <td>0.813</td>\n",
              "      <td>0.156</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  ticker                      time  \\\n",
              "0    KHC 2025-01-01 00:00:00+00:00   \n",
              "1     GE 2025-01-01 09:01:43+00:00   \n",
              "2    IEP 2025-01-01 09:01:43+00:00   \n",
              "3    HON 2025-01-01 09:01:43+00:00   \n",
              "4    CMI 2025-01-01 09:02:48+00:00   \n",
              "\n",
              "                                               title  \\\n",
              "0                   Is Kraft Heinz Stock in Trouble?   \n",
              "1  General Industrial Machinery Stocks Q3 Results...   \n",
              "2  General Industrial Machinery Stocks Q3 Results...   \n",
              "3  General Industrial Machinery Stocks Q3 Results...   \n",
              "4  Heavy Transportation Equipment Stocks Q3 Recap...   \n",
              "\n",
              "                                             content  \\\n",
              "0                   Is Kraft Heinz Stock in Trouble?   \n",
              "1  General Industrial Machinery Stocks Q3 Results...   \n",
              "2  General Industrial Machinery Stocks Q3 Results...   \n",
              "3  General Industrial Machinery Stocks Q3 Results...   \n",
              "4  Heavy Transportation Equipment Stocks Q3 Recap...   \n",
              "\n",
              "                                                link  \\\n",
              "0  https://www.fool.com/investing/2025/01/01/is-k...   \n",
              "1  https://finance.yahoo.com/news/general-industr...   \n",
              "2  https://finance.yahoo.com/news/general-industr...   \n",
              "3  https://finance.yahoo.com/news/general-industr...   \n",
              "4  https://finance.yahoo.com/news/heavy-transport...   \n",
              "\n",
              "                                             symbols tags  sentiment_polarity  \\\n",
              "0                                             KHC.US  NaN              -0.402   \n",
              "1            GE.MX,GE.US,HI.US,HON.US,IEP.US,LXFR.US  NaN               0.998   \n",
              "2            GE.MX,GE.US,HI.US,HON.US,IEP.US,LXFR.US  NaN               0.998   \n",
              "3            GE.MX,GE.US,HI.US,HON.US,IEP.US,LXFR.US  NaN               0.998   \n",
              "4  0I58.LSE,BLBD.US,CMI.US,CUM.DU,CUM.F,CUM.MU,RE...  NaN               0.999   \n",
              "\n",
              "   sentiment_neg  sentiment_neu  sentiment_pos  \n",
              "0          0.351          0.649          0.000  \n",
              "1          0.043          0.817          0.140  \n",
              "2          0.043          0.817          0.140  \n",
              "3          0.043          0.817          0.140  \n",
              "4          0.031          0.813          0.156  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import psycopg2\n",
        "import pandas as pd\n",
        "\n",
        "conn_params = {\n",
        "    \"host\": \"quest.amudhan.me\",\n",
        "    \"port\": 8812,\n",
        "    \"database\": \"qdb\",\n",
        "    \"user\": \"admin\",\n",
        "    \"password\": \"redacted\"\n",
        "}\n",
        "\n",
        "try:\n",
        "    conn = psycopg2.connect(**conn_params)\n",
        "\n",
        "    query = \"\"\"\n",
        "    SELECT * FROM stock_news WHERE time BETWEEN '2025-01-01T00:00:00Z' AND '2025-05-15T23:59:59Z'\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    df_test = pd.read_sql_query(query, conn)\n",
        "    conn.close()\n",
        "\n",
        "except Exception as e:\n",
        "    raise Exception(f\"QuestDB error: {e}\")\n",
        "\n",
        "# Ensure datetime conversion\n",
        "df_test['time'] = pd.to_datetime(df_test['time'])\n",
        "df_test.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6b56c3e2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "2    32446\n",
            "0     2381\n",
            "1     2008\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df_test[\"label\"] = df_test[\"sentiment_polarity\"].apply(mapper)\n",
        "print(df_test[\"label\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3a01f159",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.75      0.52      0.62      2381\n",
            "     neutral       0.47      0.78      0.58      2008\n",
            "    positive       0.97      0.95      0.96     32446\n",
            "\n",
            "    accuracy                           0.92     36835\n",
            "   macro avg       0.73      0.75      0.72     36835\n",
            "weighted avg       0.93      0.92      0.92     36835\n",
            "\n",
            "\n",
            "Confusion Matrix\n",
            "            pred_neg  pred_neu  pred_pos\n",
            "actual_neg      1246       544       591\n",
            "actual_neu       189      1568       251\n",
            "actual_pos       233      1257     30956\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# ─────────────────── 1.  Load model & helper  ────────────────────\n",
        "clf_tok  = AutoTokenizer.from_pretrained(\"./gptneo125_sentiment/final\")\n",
        "clf_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "               \"./gptneo125_sentiment/final\"\n",
        "            ).eval().to(\"cuda\")\n",
        "\n",
        "label_map       = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
        "inverse_map     = {v: k for k, v in label_map.items()}  # handy later\n",
        "\n",
        "@torch.inference_mode()\n",
        "def predict_label(text: str) -> tuple[int, float]:\n",
        "    \"\"\"Return (numeric_label, confidence_of_chosen_label).\"\"\"\n",
        "    toks = clf_tok(text,\n",
        "                   return_tensors=\"pt\",\n",
        "                   truncation=True,\n",
        "                   padding=True).to(\"cuda\")\n",
        "    logits = clf_model(**toks).logits\n",
        "    probs  = torch.softmax(logits, dim=-1)[0]\n",
        "    idx    = int(probs.argmax())\n",
        "    return idx, float(probs[idx])\n",
        "\n",
        "# ─────────────────── 2.  Make ground-truth labels ─────────────────\n",
        "df_test[\"label_true\"] = df_test[\"sentiment_polarity\"].apply(mapper)\n",
        "\n",
        "# ─────────────────── 3.  Run predictions  ────────────────────────\n",
        "y_true, y_pred, y_conf = [], [], []      # collect for metrics & analysis\n",
        "\n",
        "for text in df_test[\"content\"]:\n",
        "    pred_lbl, conf = predict_label(text)\n",
        "    y_pred.append(pred_lbl)\n",
        "    y_conf.append(conf)\n",
        "\n",
        "y_true = df_test[\"label_true\"].tolist()\n",
        "\n",
        "# store in DataFrame (optional but convenient)\n",
        "df_test[\"label_pred\"] = y_pred\n",
        "df_test[\"pred_conf\"]  = y_conf\n",
        "\n",
        "# ─────────────────── 4.  Evaluation  ─────────────────────────────\n",
        "print(\"\\nClassification Report\")\n",
        "print(classification_report(y_true, y_pred,\n",
        "                            target_names=[\"negative\", \"neutral\", \"positive\"]))\n",
        "\n",
        "print(\"\\nConfusion Matrix\")\n",
        "print(pd.DataFrame(confusion_matrix(y_true, y_pred),\n",
        "                   columns=[\"pred_neg\", \"pred_neu\", \"pred_pos\"],\n",
        "                   index=[\"actual_neg\", \"actual_neu\", \"actual_pos\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ab1d3515",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'label': 'negative', 'prob': 0.9980024695396423}\n"
          ]
        }
      ],
      "source": [
        "clf_tok  = AutoTokenizer.from_pretrained(\"./gptneo125_sentiment/final\")\n",
        "clf_model = AutoModelForSequenceClassification.from_pretrained(\"./gptneo125_sentiment/final\").eval().to(\"cuda\")\n",
        "\n",
        "label_map = {0:\"negative\", 1:\"neutral\", 2:\"positive\"}\n",
        "\n",
        "def predict(text):\n",
        "    tokens = clf_tok(text, return_tensors=\"pt\", truncation=True, padding=True).to(\"cuda\")\n",
        "    with torch.no_grad():\n",
        "        logits = clf_model(**tokens).logits\n",
        "    prob = torch.softmax(logits, dim=-1)[0]\n",
        "    idx  = prob.argmax().item()\n",
        "    return {\"label\": label_map[idx], \"prob\": float(prob[idx])}\n",
        "\n",
        "print(predict(f\"Tesla Sales Fell 46% in Germany. That’s Just the Latest Bad News for the Stock..\"))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
